ls
pwd
exit
ls
tar -xvf all.tar 
ls
ls -lrt
cd crawl/
ls -lrt
cd ..
ls
rm all.tar 
ls -lrt
echo $LANG
cd sqlscript/
ls
cat yrd.sql 
exit
ls
ls -lrt
chmod 777 *
ls -lrt
cd crawl/
ls -lrt
chmod 777 *
ls -lrt
cd ..
ls
cd shell/
ls -lrt
chmod 777 *
ls -lrt
cd ..
ls
cd sqlscript/
chmod 777 *
ls -lrt
cd 
ls
ls -lrt
cd log/
ls
rm *
ls -lrt
ls
cd 
ls -lrt
cd
exit
ls
cd shell/
ls
vi control.sh 
ls
vi platform_info.sh 
cat control.sh 
vi control.sh 
vi run_sql.sh 
vi platform_info.sh 
vi run_sql.sh 
ls -lrt
ls
top
cd
ls
exit
cd crawl/
ls -lrt
tar -xvf abc.tar 
ls -lrt
chmod 777 *
rm abc.tar 
ls -lrt
cd youli/
ls
ls -lrt
cd youli/
ls
cat pipelines.py
d
cd ../../sh
cd ../
cd ../../shell/
ls
sh control.sh 
exit
cd /usr/scrapy/sqlscript/
ls -lrt
tar -xvf sql.tar 
ls -lrt
rm sql.tar 
chmod 777 *
ls -lrt
ps -ef|grep run
kill 13526
ps -ef|grep run
exit
ls
cd crawl/
ls
cd paipaidai/paipaidai/
ls
tar -xvf a.tar 
ls -lrt
cd spiders/
ls -lrt
cat base.py
ls
cd sqlscript/
ls
ls -lrt
tar -xvf sql.tar 
ls -lrt
cat ppd.sql 
ls -lrt
chmod 777 *
chmod 777 *.sql
ls -lrt
rm sql.tar 
ls -lrt
crontab -e
exit
ls
ps -ef
crontab -e
crontab -l
exit
ls
cd crawl/
ls
cd ..
ls
cd log/
ls
rm *
rm -9 *
ls
rm -9 *.log
ls
rm *.log
rm -9 *.log
rm -r *.log
rm -f *.log
ls
cd ..
crontab -l
exit
ls
cd log
ls
cd ..
cd crawl/
ls
cd honglingchuangtou/
ls
cd honglingchuangtou/
ls
cd ..
cat scrapy.cfg 
cd ..
ls
cd ..
ls
cd shell/
ls
cat control.sh 
exit
ls
cd sqlscript/
ls
cat dth.sql 
ps -ef
kill -9 27173
ps -ef
kill -9 27173
exit
ls
cd crawl/
ls
cd wangdaizhijia/
ls
cd wangdaizhijia/
ls
cd spiders/
ls
vi base.py
exit
ls
cd shell/
ls
more platform_info.sh 
print u'\u62db\u5b9d\u4e07\u91d1'
exit
ls
cd crawl/
ls
cd wangdaizhijia/
ls
cd wangdaizhijia/
ls
cd spiders/
ls
vi base.py
ls -lrt
vi base.py
cd
ls
exit
pwd
exit
ls
cd sqlscript/
ls
vi platform_info_daily.sql 
ls
cd crawl/
ls
cd wangdaizhijia
ls
scrapy crawl wangdaizhijia 
cd ..
cd wangdaizhijiaP
scrapy crawl wangdaizhijiaP
cd ..
ls
cd ..
ls
cd sqlscript/
ls
more platform_info_daily.sql 
exit
ls
pwd
ls
git init
ls
git init 
scp -r * root@42.96.131.5:/home/sc  
ls
cd crawl/
ls
cd anxin/
ls
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy shell http://www.anxin.com/invest/detail504034z.html
exit
ls
cd crawl/
ls
cd ..
ls
cd config/
ls
vi list.spider 
vi list.table 
ls
cd ..
ls
cd crawl/
ls
cd ..
ls
cd shell/
ls
vi run_sql.sh 
vi platform_info.sh 
vi control.sh 
vi run_sql.sh 
shell run_sql.sh ../ anxin
shell run_sql.sh 
sh run_sql.sh ./anxin anxin
cd ..
ls
cd crawl/
ls
cd anxin/
crawl scrapy anxin
scrapy crawl anxin
ls
cd anxin/
ls
cd ..
ls
cd anxin/
ls
sudo vi pipelines.py
ls
sudo vi pipelines.py
vi pipelines.py
ls
vi items.py
ls
cd spiders/
ls
sudo vi base.py
vi base.py
ls
cd ../
ls
cd ..
ls
cd ..
scrapy anxin 
cd ..
ls
cd crawl/
ls
scrapy anxin 
scrapy crawl anxin
ls
cd anxin/
scrapy crawl anxin
sudo vi anxin/spiders/base.py
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
cd ..
ls
cd ..
ls
git init
git apt-get install git
sudo  apt-get install git
apt-get install git
sudo apt-get install git
sudo apt-get 
sudo apt-get install git
apt-get install git
su -
exit
sudo apt-get install python-scrapy
ls
sudo apt-get install python-scrapy
sudo apt-get install Xvfb
ls
cd crawl/
ls
cd itouzi/
ls
vi itouzi/spiders/base.py
scrapy crawl itouzi 
vi itouzi/spiders/base.py
scrapy crawl itouzi 
ls
cd ..
ls
cd lujinsuo/
ls
scrapy crawl lujinsuo lujinsuo lujinsuo lujinsuo 
scrapy crawl lujinsuo
cd ..
ls
cd nonobank/
find ../../ -name rate_crawler
find ../../ -name rate_crawler.py
find ../../../ -name rate_crawler.py
sudo find ../../../ -name rate_crawler.py
sudo find ../../../../ -name rate_crawler.py
sudo find ../../../../../ -name rate_crawler.py
sudo find ../../../../../ -name rate_crawler
sudo find ../../../../../ -name rate_crawler*
cd ..
ls
cd itouzi/
ls
cp ../../scrapy.py  .
ls
sudo vi itouzi/settings.py
ls
mv scrapy.py itouzi/
ls
cd itouzi/
ls
sudo vi settings.py
mv scrapy.py WebkitDownloader.py
cd ..
ls
scrapy crawl itouzi
pwd
cd itouzi/
ls
sudo vi WebkitDownloader.py 
sudo vi settings.py
ls
cp ../../../scrapy.py  .
ls
vi scrapy.py 
ls
vi scrapy.py 
mv scrapy.py WebkitDownloader.py 
LS
ls
vi WebkitDownloader.py 
cd ..
ls
scrapy crawl itouzi
ls
vi /usr/local/lib/python2.7/dist-packages/scrapy/middleware.py
ls
cd ..
cd itouzi/
cd ../..
ls
mkdir rate_crawler
cd rate_crawler/
ls
mkdir dowloader
cd dowloader/
mkdir WebkitDownloader
ls
cd ..
ls
cd ..
ls
cd scrapy/
sl
ls
cd crawl/
ls
cd itouzi/
ls
cd itouzi/
ls
mv WebkitDownloader.py ../../../rate_crawler/dowloader/WebkitDownloader/
ls
sudo vi settings.py
scrapy crawl itouzi
sudo vi settings.py
scrapy crawl itouzi
pwd
sudo vi settings.py
scrapy crawl itouzi
vi /usr/local/lib/python2.7/dist-packages/scrapy/utils/misc.py
sudo vi settings.py
scrapy crawl itouzi
ls
sudo vi settings.py
mkdir dowloader
ls
cp ../../../rate_crawler/dowloader/WebkitDownloader/WebkitDownloader.py  .
ls
mv WebkitDownloader.py dowloader/
ls
scrapy crawl itouzi
cd ..
ls
scrapy crawl itouzi
ls
cd itouzi/
sl
ls
cd dowloader/
ls
vi WebkitDownloader.py 
mv WebkitDownloader.py downloader.py
ls
mv downloader.py ../
ls
cd ..
ls
rm dowloader -r
ls
sudo vi settings.py
cd ..
scrapy crawl itouzi
sudo apt-get install gtk
sudo apt-get install python-gtk2  python-gtk2-dbg   python-gtk2-dev   python-gtk2-doc
sudo apt-get update
scrapy crawl itouzi
sudo apt-get install python-gtk2  python-gtk2-dbg   python-gtk2-dev   python-gtk2-doc
scrapy crawl itouzi
sudo apt-get install webkit
sudo apt-get install qt4 qt4-devel qt4-doc
sudo apt-get  install qtwebkit qtwebkit-devel
sudo apt-get  install webkit webkit-devel
ls
cd ../../
ls
cd webkit-server-1.0/
ls
sudo python setup.py install
ls
sudo python setup.py install
ls
cd src/
ls
cd ..
ls
cp webkit_server.py src/
sudo python setup.py install
sudo apt-get install webkit-server
sudo apt-get install python-webkit
cd ..
ls
cd crawl/
ls
cd itouzi/
ls
scrapy crawl itouzi 
sudo apt-get install jswebkit
sudo apt-get install python-jswebkit
scrapy crawl itouzi 
ls
cd ..
ls
cd weidai
ls
scrapy crawl weidai
ls
cd ..
ls
cd weidai/
ls
sudo vi weidai/spiders/
vi weidai/spiders/base.py
scrapy crawl weidai
ls
sudo vi weidai/spiders/base.py
scrapy crawl weidai
sudo vi weidai/spiders/base.py
ls
cd ..
ls
cd youli
ls
scrapy crawl youli
cd ..
ls
cd wangdaizhijia
scrapy crawl wangdaizhijia 
ls
cd ..
ls
cd wsloan
scrapy crawl wsloan
ls
cd ..
ls
cd niwodai
ls
scrapy crawl niwodai niwodai niwodai 
scrapy crawl niwodai 
ls
vi niwodai/spiders/base.py
scrapy crawl niwodai 
ls
cd ..
ls
cd datonghang
ls
scrapy crawl datonghang datonghang 
scrapy crawl datonghang 
cd ..
l
ls
cd itouzi/
ls
scrapy crawl itouzi
ls
vi itouzi/spiders/base.py
scrapy crawl itouzi
ls
vi itouzi/spiders/base.py
scrapy crawl itouzi
ls
scrapy shell http://www.itouzi.com/dinvest/list/index?type=2
vi itouzi/spiders/base.py
scrapy crawl itouzi
vi itouzi/spiders/base.py
scrapy crawl itouzi
vi itouzi/spiders/base.py
scrapy crawl itouzi
vi itouzi/spiders/base.py
scrapy crawl itouzi
vi itouzi/spiders/base.py
scrapy crawl itouzi
vi itouzi/spiders/base.py
scrapy crawl itouzi
exit
apt-get install git
sudo apt-get install git
sudo apt-get install python-scrapy
ls
su -
exit
ls
cd crawl/
ls
cd anxin/
ls
scrapy crawl anxin
scrapy shell http://www.anxin.com/invest/detail504010d.html
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
ls
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
vi anxin/spiders/base.py
scrapy crawl anxin
ls
cd ..
ls
cd anxin/
ls
vi anxin/spiders/base.py
scrapy crawl anxin
ls
cd ..
ls
cd eloan/
ls
cd eloan/
ls
cd ..
ls
scrapy crawl eloan
sudo vi eloan/spiders/base.py
vi eloan/spiders/base.py
scrapy crawl eloan
vi eloan/spiders/base.py
scrapy crawl eloan
vi eloan/spiders/base.py
scrapy crawl eloan
vi eloan/spiders/base.py
scrapy crawl eloan
vi eloan/spiders/base.py
scrapy crawl eloan
scrapy shell http://www.eloancn.com/loan/loandetail.action?tenderid=17049
vi eloan/spiders/base.py
scrapy crawl eloan
vi eloan/spiders/base.py
scrapy shell http://www.eloancn.com/loan/loandetail.action?tenderid=17049
scrapy crawl eloan
ls
vi eloan/spiders/base.py
scrapy crawl eloan
ls
cd ..
ls
cd itouzi/
ls
scrapy crawl itouzi
sudo vi itouzi/spiders/base.py
vi itouzi/spiders/base.py
scrapy crawl itouzi
scrapy shell http://www.itouzi.com/dinvest/factoring/detail?id=58775470644c452b67494674
scrapy crawl itouzi
sudo apt-get install python-scrapy
apt-get install python-scrapy
su -
exit
sudo apt-get install python-scrapy
exit
su - root
ls
cd crawl/
ls
cd wangdaizhijia
ls
cd wangdaizhijia/
ls
vi pipelines.py
ls
vi settings.py
ls
vi items.py
ls
cd spiders/
ls
vi base.py
ls
cd ..
scrapy crawl wangdaizhijia 
cd wangdaizhijia/
s
ls
vi pipelines.py
cd ..
scrapy crawl wangdaizhijia 
cd ..
ls
cd ..
ls
cd sqlscript/
ls
vi platform_info_daily.sql 
exit
