2015-09-14 14:27:22 开始运行爬虫----------lujinsuo---------------------------------------
2015-09-14 14:27:26+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: lujinsuo)
2015-09-14 14:27:26+0800 [scrapy] INFO: Optional features available: ssl, http11, boto, django
2015-09-14 14:27:26+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'lujinsuo.spiders', 'SPIDER_MODULES': ['lujinsuo.spiders'], 'BOT_NAME': 'lujinsuo'}
2015-09-14 14:27:26+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2015-09-14 14:27:27+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-09-14 14:27:27+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-09-14 14:27:28+0800 [scrapy] INFO: Enabled item pipelines: LujinsuoPipeline
2015-09-14 14:27:28+0800 [lujinsuo] INFO: Spider opened
2015-09-14 14:27:28+0800 [lujinsuo] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-09-14 14:27:28+0800 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6033
2015-09-14 14:27:28+0800 [scrapy] DEBUG: Web service listening on 127.0.0.1:6090
2015-09-14 14:27:28+0800 [lujinsuo] DEBUG: Redirecting (301) to <GET https://list.lu.com/list/productDetail?productId=235846> from <GET https://list.lufax.com/list/productDetail?productId=235846>
2015-09-14 14:27:32+0800 [lujinsuo] DEBUG: Redirecting (301) to <GET https://list.lu.com/list/productDetail?productId=235847> from <GET https://list.lufax.com/list/productDetail?productId=235847>
2015-09-14 14:27:35+0800 [lujinsuo] DEBUG: Redirecting (301) to <GET https://list.lu.com/list/productDetail?productId=235840> from <GET https://list.lufax.com/list/productDetail?productId=235840>
2015-09-14 14:27:38+0800 [lujinsuo] DEBUG: Redirecting (301) to <GET https://list.lu.com/list/productDetail?productId=235841> from <GET https://list.lufax.com/list/productDetail?productId=235841>
2015-09-14 14:27:42+0800 [lujinsuo] DEBUG: Redirecting (301) to <GET https://list.lu.com/list/productDetail?productId=235890> from <GET https://list.lufax.com/list/productDetail?productId=235890>
2015-09-14 14:27:46+0800 [lujinsuo] DEBUG: Redirecting (301) to <GET https://list.lu.com/list/productDetail?productId=235879> from <GET https://list.lufax.com/list/productDetail?productId=235879>
2015-09-14 14:27:49+0800 [lujinsuo] DEBUG: Redirecting (301) to <GET https://list.lu.com/list/productDetail?productId=235859> from <GET https://list.lufax.com/list/productDetail?productId=235859>
2015-09-14 14:27:53+0800 [lujinsuo] DEBUG: Redirecting (301) to <GET https://list.lu.com/list/productDetail?productId=235868> from <GET https://list.lufax.com/list/productDetail?productId=235868>
2015-09-14 14:27:56+0800 [lujinsuo] DEBUG: Redirecting (301) to <GET https://list.lu.com/list/productDetail?productId=235869> from <GET https://list.lufax.com/list/productDetail?productId=235869>
2015-09-14 14:28:00+0800 [lujinsuo] DEBUG: Redirecting (301) to <GET https://list.lu.com/list/productDetail?productId=235867> from <GET https://list.lufax.com/list/productDetail?productId=235867>
2015-09-14 14:28:03+0800 [lujinsuo] DEBUG: Redirecting (301) to <GET https://list.lu.com/list/productDetail?productId=235880> from <GET https://list.lufax.com/list/productDetail?productId=235880>
2015-09-14 14:28:07+0800 [lujinsuo] DEBUG: Redirecting (301) to <GET https://list.lu.com/list/productDetail?productId=235860> from <GET https://list.lufax.com/list/productDetail?productId=235860>
2015-09-14 14:28:10+0800 [lujinsuo] DEBUG: Redirecting (301) to <GET https://list.lu.com/list/productDetail?productId=235878> from <GET https://list.lufax.com/list/productDetail?productId=235878>
2015-09-14 14:28:13+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET http://www.lu.com/notFound.html> from <GET https://list.lu.com/list/productDetail?productId=235846>
2015-09-14 14:28:16+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET http://www.lu.com/notFound.html> from <GET https://list.lu.com/list/productDetail?productId=235847>
2015-09-14 14:28:19+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET http://www.lu.com/notFound.html> from <GET https://list.lu.com/list/productDetail?productId=235840>
2015-09-14 14:28:23+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET http://www.lu.com/notFound.html> from <GET https://list.lu.com/list/productDetail?productId=235841>
2015-09-14 14:28:27+0800 [lujinsuo] DEBUG: Crawled (200) <GET https://list.lu.com/list/productDetail?productId=235890> (referer: None)
2015-09-14 14:28:27+0800 [lujinsuo] ERROR: Spider error processing <GET https://list.lu.com/list/productDetail?productId=235890>
	Traceback (most recent call last):
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 824, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 638, in _tick
	    taskObj._oneWorkUnit()
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 484, in _oneWorkUnit
	    result = next(self._iterator)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 57, in <genexpr>
	    work = (callable(elem, *args, **named) for elem in iterable)
	--- <exception caught here> ---
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 96, in iter_errback
	    yield next(it)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/offsite.py", line 26, in process_spider_output
	    for x in result:
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/referer.py", line 22, in <genexpr>
	    return (_set_referer(r) for r in result or ())
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/urllength.py", line 33, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/depth.py", line 50, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/scrapy/crawl/lujinsuo/lujinsuo/spiders/base.py", line 60, in parse
	    amount = sel.xpath('//ul[@class=\"clearfix detail-info-list\"]/li/p/strong/text()').extract()[0]
	exceptions.IndexError: list index out of range
	
2015-09-14 14:28:28+0800 [lujinsuo] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2015-09-14 14:28:31+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET http://www.lu.com/notFound.html> from <GET https://list.lu.com/list/productDetail?productId=235879>
2015-09-14 14:28:34+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET http://www.lu.com/notFound.html> from <GET https://list.lu.com/list/productDetail?productId=235859>
2015-09-14 14:28:39+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET http://www.lu.com/notFound.html> from <GET https://list.lu.com/list/productDetail?productId=235868>
2015-09-14 14:28:43+0800 [lujinsuo] DEBUG: Crawled (200) <GET https://list.lu.com/list/productDetail?productId=235869> (referer: None)
2015-09-14 14:28:43+0800 [lujinsuo] ERROR: Spider error processing <GET https://list.lu.com/list/productDetail?productId=235869>
	Traceback (most recent call last):
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 824, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 638, in _tick
	    taskObj._oneWorkUnit()
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 484, in _oneWorkUnit
	    result = next(self._iterator)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 57, in <genexpr>
	    work = (callable(elem, *args, **named) for elem in iterable)
	--- <exception caught here> ---
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 96, in iter_errback
	    yield next(it)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/offsite.py", line 26, in process_spider_output
	    for x in result:
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/referer.py", line 22, in <genexpr>
	    return (_set_referer(r) for r in result or ())
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/urllength.py", line 33, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/depth.py", line 50, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/scrapy/crawl/lujinsuo/lujinsuo/spiders/base.py", line 60, in parse
	    amount = sel.xpath('//ul[@class=\"clearfix detail-info-list\"]/li/p/strong/text()').extract()[0]
	exceptions.IndexError: list index out of range
	
2015-09-14 14:28:46+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET http://www.lu.com/notFound.html> from <GET https://list.lu.com/list/productDetail?productId=235867>
2015-09-14 14:28:51+0800 [lujinsuo] DEBUG: Crawled (200) <GET https://list.lu.com/list/productDetail?productId=235880> (referer: None)
2015-09-14 14:28:51+0800 [lujinsuo] ERROR: Spider error processing <GET https://list.lu.com/list/productDetail?productId=235880>
	Traceback (most recent call last):
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 824, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 638, in _tick
	    taskObj._oneWorkUnit()
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 484, in _oneWorkUnit
	    result = next(self._iterator)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 57, in <genexpr>
	    work = (callable(elem, *args, **named) for elem in iterable)
	--- <exception caught here> ---
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 96, in iter_errback
	    yield next(it)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/offsite.py", line 26, in process_spider_output
	    for x in result:
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/referer.py", line 22, in <genexpr>
	    return (_set_referer(r) for r in result or ())
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/urllength.py", line 33, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/depth.py", line 50, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/scrapy/crawl/lujinsuo/lujinsuo/spiders/base.py", line 60, in parse
	    amount = sel.xpath('//ul[@class=\"clearfix detail-info-list\"]/li/p/strong/text()').extract()[0]
	exceptions.IndexError: list index out of range
	
2015-09-14 14:28:55+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET http://www.lu.com/notFound.html> from <GET https://list.lu.com/list/productDetail?productId=235860>
2015-09-14 14:28:57+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET http://www.lu.com/notFound.html> from <GET https://list.lu.com/list/productDetail?productId=235878>
2015-09-14 14:29:02+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://www.lu.com/notFound.html> from <GET http://www.lu.com/notFound.html>
2015-09-14 14:29:06+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://www.lu.com/notFound.html> from <GET http://www.lu.com/notFound.html>
2015-09-14 14:29:10+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://www.lu.com/notFound.html> from <GET http://www.lu.com/notFound.html>
2015-09-14 14:29:12+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://www.lu.com/notFound.html> from <GET http://www.lu.com/notFound.html>
2015-09-14 14:29:16+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://www.lu.com/notFound.html> from <GET http://www.lu.com/notFound.html>
2015-09-14 14:29:19+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://www.lu.com/notFound.html> from <GET http://www.lu.com/notFound.html>
2015-09-14 14:29:24+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://www.lu.com/notFound.html> from <GET http://www.lu.com/notFound.html>
2015-09-14 14:29:28+0800 [lujinsuo] INFO: Crawled 3 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2015-09-14 14:29:28+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://www.lu.com/notFound.html> from <GET http://www.lu.com/notFound.html>
2015-09-14 14:29:32+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://www.lu.com/notFound.html> from <GET http://www.lu.com/notFound.html>
2015-09-14 14:29:34+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://www.lu.com/notFound.html> from <GET http://www.lu.com/notFound.html>
2015-09-14 14:29:38+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://promo.lu.com/transfer/v1/notFound.html> from <GET https://www.lu.com/notFound.html>
2015-09-14 14:29:42+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://promo.lu.com/transfer/v1/notFound.html> from <GET https://www.lu.com/notFound.html>
2015-09-14 14:29:45+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://promo.lu.com/transfer/v1/notFound.html> from <GET https://www.lu.com/notFound.html>
2015-09-14 14:29:48+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://promo.lu.com/transfer/v1/notFound.html> from <GET https://www.lu.com/notFound.html>
2015-09-14 14:29:52+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://promo.lu.com/transfer/v1/notFound.html> from <GET https://www.lu.com/notFound.html>
2015-09-14 14:29:56+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://promo.lu.com/transfer/v1/notFound.html> from <GET https://www.lu.com/notFound.html>
2015-09-14 14:30:00+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://promo.lu.com/transfer/v1/notFound.html> from <GET https://www.lu.com/notFound.html>
2015-09-14 14:30:04+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://promo.lu.com/transfer/v1/notFound.html> from <GET https://www.lu.com/notFound.html>
2015-09-14 14:30:06+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://promo.lu.com/transfer/v1/notFound.html> from <GET https://www.lu.com/notFound.html>
2015-09-14 14:30:10+0800 [lujinsuo] DEBUG: Redirecting (302) to <GET https://promo.lu.com/transfer/v1/notFound.html> from <GET https://www.lu.com/notFound.html>
2015-09-14 14:30:12+0800 [lujinsuo] DEBUG: Crawled (200) <GET https://promo.lu.com/transfer/v1/notFound.html> (referer: None)
2015-09-14 14:30:12+0800 [lujinsuo] ERROR: Spider error processing <GET https://promo.lu.com/transfer/v1/notFound.html>
	Traceback (most recent call last):
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 824, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 638, in _tick
	    taskObj._oneWorkUnit()
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 484, in _oneWorkUnit
	    result = next(self._iterator)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 57, in <genexpr>
	    work = (callable(elem, *args, **named) for elem in iterable)
	--- <exception caught here> ---
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 96, in iter_errback
	    yield next(it)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/offsite.py", line 26, in process_spider_output
	    for x in result:
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/referer.py", line 22, in <genexpr>
	    return (_set_referer(r) for r in result or ())
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/urllength.py", line 33, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/depth.py", line 50, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/scrapy/crawl/lujinsuo/lujinsuo/spiders/base.py", line 60, in parse
	    amount = sel.xpath('//ul[@class=\"clearfix detail-info-list\"]/li/p/strong/text()').extract()[0]
	exceptions.IndexError: list index out of range
	
2015-09-14 14:30:16+0800 [lujinsuo] DEBUG: Crawled (200) <GET https://promo.lu.com/transfer/v1/notFound.html> (referer: None)
2015-09-14 14:30:16+0800 [lujinsuo] ERROR: Spider error processing <GET https://promo.lu.com/transfer/v1/notFound.html>
	Traceback (most recent call last):
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 824, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 638, in _tick
	    taskObj._oneWorkUnit()
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 484, in _oneWorkUnit
	    result = next(self._iterator)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 57, in <genexpr>
	    work = (callable(elem, *args, **named) for elem in iterable)
	--- <exception caught here> ---
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 96, in iter_errback
	    yield next(it)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/offsite.py", line 26, in process_spider_output
	    for x in result:
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/referer.py", line 22, in <genexpr>
	    return (_set_referer(r) for r in result or ())
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/urllength.py", line 33, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/depth.py", line 50, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/scrapy/crawl/lujinsuo/lujinsuo/spiders/base.py", line 60, in parse
	    amount = sel.xpath('//ul[@class=\"clearfix detail-info-list\"]/li/p/strong/text()').extract()[0]
	exceptions.IndexError: list index out of range
	
2015-09-14 14:30:20+0800 [lujinsuo] DEBUG: Crawled (200) <GET https://promo.lu.com/transfer/v1/notFound.html> (referer: None)
2015-09-14 14:30:20+0800 [lujinsuo] ERROR: Spider error processing <GET https://promo.lu.com/transfer/v1/notFound.html>
	Traceback (most recent call last):
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 824, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 638, in _tick
	    taskObj._oneWorkUnit()
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 484, in _oneWorkUnit
	    result = next(self._iterator)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 57, in <genexpr>
	    work = (callable(elem, *args, **named) for elem in iterable)
	--- <exception caught here> ---
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 96, in iter_errback
	    yield next(it)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/offsite.py", line 26, in process_spider_output
	    for x in result:
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/referer.py", line 22, in <genexpr>
	    return (_set_referer(r) for r in result or ())
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/urllength.py", line 33, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/depth.py", line 50, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/scrapy/crawl/lujinsuo/lujinsuo/spiders/base.py", line 60, in parse
	    amount = sel.xpath('//ul[@class=\"clearfix detail-info-list\"]/li/p/strong/text()').extract()[0]
	exceptions.IndexError: list index out of range
	
2015-09-14 14:30:24+0800 [lujinsuo] DEBUG: Crawled (200) <GET https://promo.lu.com/transfer/v1/notFound.html> (referer: None)
2015-09-14 14:30:24+0800 [lujinsuo] ERROR: Spider error processing <GET https://promo.lu.com/transfer/v1/notFound.html>
	Traceback (most recent call last):
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 824, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 638, in _tick
	    taskObj._oneWorkUnit()
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 484, in _oneWorkUnit
	    result = next(self._iterator)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 57, in <genexpr>
	    work = (callable(elem, *args, **named) for elem in iterable)
	--- <exception caught here> ---
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 96, in iter_errback
	    yield next(it)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/offsite.py", line 26, in process_spider_output
	    for x in result:
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/referer.py", line 22, in <genexpr>
	    return (_set_referer(r) for r in result or ())
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/urllength.py", line 33, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/depth.py", line 50, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/scrapy/crawl/lujinsuo/lujinsuo/spiders/base.py", line 60, in parse
	    amount = sel.xpath('//ul[@class=\"clearfix detail-info-list\"]/li/p/strong/text()').extract()[0]
	exceptions.IndexError: list index out of range
	
2015-09-14 14:30:27+0800 [lujinsuo] DEBUG: Crawled (200) <GET https://promo.lu.com/transfer/v1/notFound.html> (referer: None)
2015-09-14 14:30:27+0800 [lujinsuo] ERROR: Spider error processing <GET https://promo.lu.com/transfer/v1/notFound.html>
	Traceback (most recent call last):
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 824, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 638, in _tick
	    taskObj._oneWorkUnit()
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 484, in _oneWorkUnit
	    result = next(self._iterator)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 57, in <genexpr>
	    work = (callable(elem, *args, **named) for elem in iterable)
	--- <exception caught here> ---
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 96, in iter_errback
	    yield next(it)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/offsite.py", line 26, in process_spider_output
	    for x in result:
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/referer.py", line 22, in <genexpr>
	    return (_set_referer(r) for r in result or ())
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/urllength.py", line 33, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/depth.py", line 50, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/scrapy/crawl/lujinsuo/lujinsuo/spiders/base.py", line 60, in parse
	    amount = sel.xpath('//ul[@class=\"clearfix detail-info-list\"]/li/p/strong/text()').extract()[0]
	exceptions.IndexError: list index out of range
	
2015-09-14 14:30:28+0800 [lujinsuo] INFO: Crawled 8 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2015-09-14 14:30:30+0800 [lujinsuo] DEBUG: Crawled (200) <GET https://promo.lu.com/transfer/v1/notFound.html> (referer: None)
2015-09-14 14:30:30+0800 [lujinsuo] ERROR: Spider error processing <GET https://promo.lu.com/transfer/v1/notFound.html>
	Traceback (most recent call last):
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 824, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 638, in _tick
	    taskObj._oneWorkUnit()
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 484, in _oneWorkUnit
	    result = next(self._iterator)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 57, in <genexpr>
	    work = (callable(elem, *args, **named) for elem in iterable)
	--- <exception caught here> ---
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 96, in iter_errback
	    yield next(it)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/offsite.py", line 26, in process_spider_output
	    for x in result:
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/referer.py", line 22, in <genexpr>
	    return (_set_referer(r) for r in result or ())
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/urllength.py", line 33, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/depth.py", line 50, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/scrapy/crawl/lujinsuo/lujinsuo/spiders/base.py", line 60, in parse
	    amount = sel.xpath('//ul[@class=\"clearfix detail-info-list\"]/li/p/strong/text()').extract()[0]
	exceptions.IndexError: list index out of range
	
2015-09-14 14:30:33+0800 [lujinsuo] DEBUG: Crawled (200) <GET https://promo.lu.com/transfer/v1/notFound.html> (referer: None)
2015-09-14 14:30:33+0800 [lujinsuo] ERROR: Spider error processing <GET https://promo.lu.com/transfer/v1/notFound.html>
	Traceback (most recent call last):
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 824, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 638, in _tick
	    taskObj._oneWorkUnit()
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 484, in _oneWorkUnit
	    result = next(self._iterator)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 57, in <genexpr>
	    work = (callable(elem, *args, **named) for elem in iterable)
	--- <exception caught here> ---
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 96, in iter_errback
	    yield next(it)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/offsite.py", line 26, in process_spider_output
	    for x in result:
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/referer.py", line 22, in <genexpr>
	    return (_set_referer(r) for r in result or ())
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/urllength.py", line 33, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/depth.py", line 50, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/scrapy/crawl/lujinsuo/lujinsuo/spiders/base.py", line 60, in parse
	    amount = sel.xpath('//ul[@class=\"clearfix detail-info-list\"]/li/p/strong/text()').extract()[0]
	exceptions.IndexError: list index out of range
	
2015-09-14 14:30:36+0800 [lujinsuo] DEBUG: Crawled (200) <GET https://promo.lu.com/transfer/v1/notFound.html> (referer: None)
2015-09-14 14:30:36+0800 [lujinsuo] ERROR: Spider error processing <GET https://promo.lu.com/transfer/v1/notFound.html>
	Traceback (most recent call last):
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 824, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 638, in _tick
	    taskObj._oneWorkUnit()
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 484, in _oneWorkUnit
	    result = next(self._iterator)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 57, in <genexpr>
	    work = (callable(elem, *args, **named) for elem in iterable)
	--- <exception caught here> ---
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 96, in iter_errback
	    yield next(it)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/offsite.py", line 26, in process_spider_output
	    for x in result:
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/referer.py", line 22, in <genexpr>
	    return (_set_referer(r) for r in result or ())
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/urllength.py", line 33, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/depth.py", line 50, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/scrapy/crawl/lujinsuo/lujinsuo/spiders/base.py", line 60, in parse
	    amount = sel.xpath('//ul[@class=\"clearfix detail-info-list\"]/li/p/strong/text()').extract()[0]
	exceptions.IndexError: list index out of range
	
2015-09-14 14:30:39+0800 [lujinsuo] DEBUG: Crawled (200) <GET https://promo.lu.com/transfer/v1/notFound.html> (referer: None)
2015-09-14 14:30:39+0800 [lujinsuo] ERROR: Spider error processing <GET https://promo.lu.com/transfer/v1/notFound.html>
	Traceback (most recent call last):
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 824, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 638, in _tick
	    taskObj._oneWorkUnit()
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 484, in _oneWorkUnit
	    result = next(self._iterator)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 57, in <genexpr>
	    work = (callable(elem, *args, **named) for elem in iterable)
	--- <exception caught here> ---
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 96, in iter_errback
	    yield next(it)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/offsite.py", line 26, in process_spider_output
	    for x in result:
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/referer.py", line 22, in <genexpr>
	    return (_set_referer(r) for r in result or ())
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/urllength.py", line 33, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/depth.py", line 50, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/scrapy/crawl/lujinsuo/lujinsuo/spiders/base.py", line 60, in parse
	    amount = sel.xpath('//ul[@class=\"clearfix detail-info-list\"]/li/p/strong/text()').extract()[0]
	exceptions.IndexError: list index out of range
	
2015-09-14 14:30:43+0800 [lujinsuo] DEBUG: Crawled (200) <GET https://promo.lu.com/transfer/v1/notFound.html> (referer: None)
2015-09-14 14:30:43+0800 [lujinsuo] ERROR: Spider error processing <GET https://promo.lu.com/transfer/v1/notFound.html>
	Traceback (most recent call last):
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 824, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 638, in _tick
	    taskObj._oneWorkUnit()
	  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/task.py", line 484, in _oneWorkUnit
	    result = next(self._iterator)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 57, in <genexpr>
	    work = (callable(elem, *args, **named) for elem in iterable)
	--- <exception caught here> ---
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/utils/defer.py", line 96, in iter_errback
	    yield next(it)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/offsite.py", line 26, in process_spider_output
	    for x in result:
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/referer.py", line 22, in <genexpr>
	    return (_set_referer(r) for r in result or ())
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/urllength.py", line 33, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/local/lib/python2.7/dist-packages/scrapy/contrib/spidermiddleware/depth.py", line 50, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/scrapy/crawl/lujinsuo/lujinsuo/spiders/base.py", line 60, in parse
	    amount = sel.xpath('//ul[@class=\"clearfix detail-info-list\"]/li/p/strong/text()').extract()[0]
	exceptions.IndexError: list index out of range
	
2015-09-14 14:30:43+0800 [lujinsuo] INFO: Closing spider (finished)
2015-09-14 14:30:43+0800 [lujinsuo] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 13209,
	 'downloader/request_count': 56,
	 'downloader/request_method_count/GET': 56,
	 'downloader/response_bytes': 161714,
	 'downloader/response_count': 56,
	 'downloader/response_status_count/200': 13,
	 'downloader/response_status_count/301': 13,
	 'downloader/response_status_count/302': 30,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2015, 9, 14, 6, 30, 43, 784434),
	 'log_count/DEBUG': 58,
	 'log_count/ERROR': 13,
	 'log_count/INFO': 10,
	 'response_received_count': 13,
	 'scheduler/dequeued': 56,
	 'scheduler/dequeued/memory': 56,
	 'scheduler/enqueued': 56,
	 'scheduler/enqueued/memory': 56,
	 'spider_exceptions/IndexError': 13,
	 'start_time': datetime.datetime(2015, 9, 14, 6, 27, 28, 9204)}
2015-09-14 14:30:43+0800 [lujinsuo] INFO: Spider closed (finished)
2015-09-14 14:30:53 爬取结束-------------lujinsuo---------------------------------------
